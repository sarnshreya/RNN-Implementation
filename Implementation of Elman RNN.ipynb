# Constructing RNN from RNNCell
import torch
import torch.nn as nn

class ElmanRNN(nn.Module):
   
   def __init__(self, input_size, hidden_size, batch_first = False):
    # input_size = size of the input vector
    # hidden_vector_size = size of the hidden vector
    # batch_first = whether the 0th dimension is a batch

      super(ElmanRNN, self).__init__()
      self.RNNCell = nn.RNNCell(input_size, hidden_vector_size)
      self.batch_first = batch_first
      self.hidden_size = hidden_size

#Intialize the initial hidden states
   def _initial_hidden(self, batch_size):
     return torch.zeroes((batch_size, self.hidden_size))

#The forward pass of the ElmanRNN to calculate the output vectors
   def forward(self, x_in, initial_hidden = None):
      # x_in (torch.Tensor): input data tensor
      # initial_hidden (torch.Tensor): initial hidden state vector for the RNN 
      # Returns hiddens (torch.Tensor): The outputs of RNN at each time step.

    if self.batch_first:
      batch_size, seq_size, feat_size = x_in.size()
      x_in = x_in.permute(1, 0, 2)
    else:
      seq_size, batch_size, feat_size = x_in.size()


    hiddens = [] #output of RNN at each time

    if initial_hidden is None:
      initial_hidden = self._initial_hidden(batch_size)
      initial_hidden = initial_hidden.to(x_in.device)

    hidden_t = initial_hidden
    for t in range(seq_size):
      hidden_t = self.rnn_cell(x_in[t], hidden_t)
      hiddens.append(hidden_t)

    hiddens = torch.stack(hiddens)

    if self.batch_first:
      hiddens = hiddens.permmute(1,0,2)

    return hiddens
